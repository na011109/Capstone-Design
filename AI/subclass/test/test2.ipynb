{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Topic 0: 0.014*\"we're\" + 0.013*\"heart\" + 0.011*\"there's\" + 0.011*\"comes\" + 0.010*\"must\" + 0.010*\"get\" + 0.010*\"clearing\" + 0.009*\"willing\" + 0.009*\"wish\" + 0.009*\"can't\"\n",
      "--------------------\n",
      "Topic 1: 0.022*\"we're\" + 0.013*\"comes\" + 0.013*\"there's\" + 0.012*\"heart\" + 0.011*\"seek\" + 0.010*\"good\" + 0.010*\"magic\" + 0.010*\"well,\" + 0.010*\"let's\" + 0.010*\"full\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lch85\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÏÖã\n",
    "documents = [\n",
    "    \"I can't believe we're really doing this, going into the enchanted forest.\"\n",
    "    \"Yeah, it's been my dream since I was a kid.\"\n",
    "    \"Your dream? I thought you were afraid of magic.\"\n",
    "    \"I was, but dreams can change, can't they?\"\n",
    "    \"Sure, as long as you're ready for whatever comes next.\"\n",
    "    \"Are you saying there's something we should worry about?\"\n",
    "    \"You can never be too sure, especially when magic is involved.\"\n",
    "    \"But we have each other, right? That should count for something.\"\n",
    "    \"Absolutely, friendship is the most powerful magic of all.\"\n",
    "    \"Just promise me one thing: if things get tough, you won't leave me behind.\"\n",
    "    \"I promise, not only because of our friendship but also because we're stronger together.\"\n",
    "    \"Good, because we're about to cross the threshold, and there's no turning back.\"\n",
    "    \"As we step in, I can feel the energy change. Can you?\"\n",
    "    \"Yes, it's like we've just walked into another dimension.\"\n",
    "    \"Look, there's a clearing ahead. Should we go there?\"\n",
    "    \"Might as well, it could be a good place to get our bearings.\"\n",
    "    \"The clearing is beautiful, full of luminescent plants and mysterious creatures.\"\n",
    "    \"It's enchanting, but let's not forget why we're here.\"\n",
    "    \"Right, we need to find the Heart of the Forest. It's said to grant a single wish to those who find it.\"\n",
    "    \"The wish can be anything?\"\n",
    "    \"Yes, but it comes with a price, and we must be willing to pay it.\"\n",
    "    \"Well, if it's for a good cause, I'm willing to take the risk.\"\n",
    "    \"Me too, but let's be cautious. The forest is full of tricks and illusions.\"\n",
    "    \"Agreed, sticking together is our best chance of finding it and making it out alive.\"\n",
    "    \"Suddenly, a soft voice echoes, 'Who dares to seek the Heart of the Forest?'\"\n",
    "    \"It must be the Guardian. What should we say?\"\n",
    "    \"Let's be honest. We seek it to bring balance to our world.\"\n",
    "    \"The Guardian seems pleased. 'Very well, you may proceed. But remember, the Heart will test you both.'\"\n",
    "    \"We nod, knowing the real journey has just begun.\"\n",
    "    \"Our hands tighten around each other's. Whatever comes next, we're ready.\"\n",
    "]\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tokenized_data = []\n",
    "for doc in documents:\n",
    "    tokens = doc.lower().split()\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokenized_data.append(filtered_tokens)\n",
    "\n",
    "# ÏÇ¨Ï†ÑÍ≥º ÏΩîÌçºÏä§ ÏÉùÏÑ±\n",
    "dictionary = Dictionary(tokenized_data)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_data]\n",
    "\n",
    "# LDA Î™®Îç∏ ÌïôÏäµ üòé\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2)\n",
    "\n",
    "# ÌÜ†ÌîΩ Ï∂úÎ†• üòä\n",
    "topics = lda_model.print_topics()\n",
    "for topic in topics:\n",
    "    print('-' * 20)\n",
    "    print(f\"Topic {topic[0]}: {topic[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: there, all, absolutely, powerful, dreams\n",
      "Topic 1: well, wish, something, willing, anything\n",
      "Topic 2: dream, let, say, guardian, must\n",
      "Topic 3: promise, especially, never, involved, also\n",
      "Topic 4: re, we, here, forget, enchanting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lch85\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÏÖã\n",
    "documents = [\n",
    "    \"I can't believe we're really doing this, going into the enchanted forest.\",\n",
    "    \"Yeah, it's been my dream since I was a kid.\",\n",
    "    \"Your dream? I thought you were afraid of magic.\",\n",
    "    \"I was, but dreams can change, can't they?\",\n",
    "    \"Sure, as long as you're ready for whatever comes next.\",\n",
    "    \"Are you saying there's something we should worry about?\",\n",
    "    \"You can never be too sure, especially when magic is involved.\",\n",
    "    \"But we have each other, right? That should count for something.\",\n",
    "    \"Absolutely, friendship is the most powerful magic of all.\",\n",
    "    \"Just promise me one thing: if things get tough, you won't leave me behind.\",\n",
    "    \"I promise, not only because of our friendship but also because we're stronger together.\",\n",
    "    \"Good, because we're about to cross the threshold, and there's no turning back.\",\n",
    "    \"As we step in, I can feel the energy change. Can you?\",\n",
    "    \"Yes, it's like we've just walked into another dimension.\",\n",
    "    \"Look, there's a clearing ahead. Should we go there?\",\n",
    "    \"Might as well, it could be a good place to get our bearings.\",\n",
    "    \"The clearing is beautiful, full of luminescent plants and mysterious creatures.\",\n",
    "    \"It's enchanting, but let's not forget why we're here.\",\n",
    "    \"Right, we need to find the Heart of the Forest. It's said to grant a single wish to those who find it.\",\n",
    "    \"The wish can be anything?\",\n",
    "    \"Yes, but it comes with a price, and we must be willing to pay it.\",\n",
    "    \"Well, if it's for a good cause, I'm willing to take the risk.\",\n",
    "    \"Me too, but let's be cautious. The forest is full of tricks and illusions.\",\n",
    "    \"Agreed, sticking together is our best chance of finding it and making it out alive.\",\n",
    "    \"Suddenly, a soft voice echoes, 'Who dares to seek the Heart of the Forest?'\",\n",
    "    \"It must be the Guardian. What should we say?\",\n",
    "    \"Let's be honest. We seek it to bring balance to our world.\",\n",
    "    \"The Guardian seems pleased. 'Very well, you may proceed. But remember, the Heart will test you both.'\",\n",
    "    \"We nod, knowing the real journey has just begun.\",\n",
    "    \"Our hands tighten around each other's. Whatever comes next, we're ready.\"\n",
    "]\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "documents = [ ' '.join([word for word in document.lower().split() if word not in stop_words]) for document in documents]\n",
    "\n",
    "# TF-IDF Î≤°ÌÑ∞Ìôî\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# LDA Î™®Îç∏ÎßÅ\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# ÌÜ†ÌîΩ Î™®Îç∏ ÌèâÍ∞Ä\n",
    "topic_words = lda.components_.argsort(axis=1)[:, ::-1]\n",
    "for i in range(lda.n_components):\n",
    "    top_words = [vectorizer.get_feature_names_out()[j] for j in topic_words[i, :5]]\n",
    "    print(f\"Topic {i}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î¨∏Ïû• 1Ïùò ÏÉÅÏúÑ 5 TF-IDF Îã®Ïñ¥:\n",
      "forest      0.278693\n",
      "comes       0.209020\n",
      "good        0.209020\n",
      "heart       0.209020\n",
      "just        0.209020\n",
      "let         0.209020\n",
      "magic       0.209020\n",
      "change      0.139347\n",
      "clearing    0.139347\n",
      "dream       0.139347\n",
      "Name: 0, dtype: float64\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "documents2 = [\n",
    "    \"I can't believe we're really doing this, going into the enchanted forest.\"\n",
    "    \"Yeah, it's been my dream since I was a kid.\"\n",
    "    \"Your dream? I thought you were afraid of magic.\"\n",
    "    \"I was, but dreams can change, can't they?\"\n",
    "    \"Sure, as long as you're ready for whatever comes next.\"\n",
    "    \"Are you saying there's something we should worry about?\"\n",
    "    \"You can never be too sure, especially when magic is involved.\"\n",
    "    \"But we have each other, right? That should count for something.\"\n",
    "    \"Absolutely, friendship is the most powerful magic of all.\"\n",
    "    \"Just promise me one thing: if things get tough, you won't leave me behind.\"\n",
    "    \"I promise, not only because of our friendship but also because we're stronger together.\"\n",
    "    \"Good, because we're about to cross the threshold, and there's no turning back.\"\n",
    "    \"As we step in, I can feel the energy change. Can you?\"\n",
    "    \"Yes, it's like we've just walked into another dimension.\"\n",
    "    \"Look, there's a clearing ahead. Should we go there?\"\n",
    "    \"Might as well, it could be a good place to get our bearings.\"\n",
    "    \"The clearing is beautiful, full of luminescent plants and mysterious creatures.\"\n",
    "    \"It's enchanting, but let's not forget why we're here.\"\n",
    "    \"Right, we need to find the Heart of the Forest. It's said to grant a single wish to those who find it.\"\n",
    "    \"The wish can be anything?\"\n",
    "    \"Yes, but it comes with a price, and we must be willing to pay it.\"\n",
    "    \"Well, if it's for a good cause, I'm willing to take the risk.\"\n",
    "    \"Me too, but let's be cautious. The forest is full of tricks and illusions.\"\n",
    "    \"Agreed, sticking together is our best chance of finding it and making it out alive.\"\n",
    "    \"Suddenly, a soft voice echoes, 'Who dares to seek the Heart of the Forest?'\"\n",
    "    \"It must be the Guardian. What should we say?\"\n",
    "    \"Let's be honest. We seek it to bring balance to our world.\"\n",
    "    \"The Guardian seems pleased. 'Very well, you may proceed. But remember, the Heart will test you both.'\"\n",
    "    \"We nod, knowing the real journey has just begun.\"\n",
    "    \"Our hands tighten around each other's. Whatever comes next, we're ready.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents2)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "dense = X.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "for i, row in df.iterrows():\n",
    "    top_five = row.nlargest(10)\n",
    "    print(f\"Î¨∏Ïû• {i+1}Ïùò ÏÉÅÏúÑ 5 TF-IDF Îã®Ïñ¥:\")\n",
    "    print(top_five)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Î¨∏Ïû• 1Ïùò N-grams ---\n",
      "('I', \"can't\")\n",
      "(\"can't\", 'believe')\n",
      "('believe', \"we're\")\n",
      "(\"we're\", 'really')\n",
      "('really', 'doing')\n",
      "('doing', 'this,')\n",
      "('this,', 'going')\n",
      "('going', 'into')\n",
      "('into', 'the')\n",
      "('the', 'enchanted')\n",
      "('enchanted', 'forest.Yeah,')\n",
      "('forest.Yeah,', \"it's\")\n",
      "(\"it's\", 'been')\n",
      "('been', 'my')\n",
      "('my', 'dream')\n",
      "('dream', 'since')\n",
      "('since', 'I')\n",
      "('I', 'was')\n",
      "('was', 'a')\n",
      "('a', 'kid.Your')\n",
      "('kid.Your', 'dream?')\n",
      "('dream?', 'I')\n",
      "('I', 'thought')\n",
      "('thought', 'you')\n",
      "('you', 'were')\n",
      "('were', 'afraid')\n",
      "('afraid', 'of')\n",
      "('of', 'magic.I')\n",
      "('magic.I', 'was,')\n",
      "('was,', 'but')\n",
      "('but', 'dreams')\n",
      "('dreams', 'can')\n",
      "('can', 'change,')\n",
      "('change,', \"can't\")\n",
      "(\"can't\", 'they?Sure,')\n",
      "('they?Sure,', 'as')\n",
      "('as', 'long')\n",
      "('long', 'as')\n",
      "('as', \"you're\")\n",
      "(\"you're\", 'ready')\n",
      "('ready', 'for')\n",
      "('for', 'whatever')\n",
      "('whatever', 'comes')\n",
      "('comes', 'next.Are')\n",
      "('next.Are', 'you')\n",
      "('you', 'saying')\n",
      "('saying', \"there's\")\n",
      "(\"there's\", 'something')\n",
      "('something', 'we')\n",
      "('we', 'should')\n",
      "('should', 'worry')\n",
      "('worry', 'about?You')\n",
      "('about?You', 'can')\n",
      "('can', 'never')\n",
      "('never', 'be')\n",
      "('be', 'too')\n",
      "('too', 'sure,')\n",
      "('sure,', 'especially')\n",
      "('especially', 'when')\n",
      "('when', 'magic')\n",
      "('magic', 'is')\n",
      "('is', 'involved.But')\n",
      "('involved.But', 'we')\n",
      "('we', 'have')\n",
      "('have', 'each')\n",
      "('each', 'other,')\n",
      "('other,', 'right?')\n",
      "('right?', 'That')\n",
      "('That', 'should')\n",
      "('should', 'count')\n",
      "('count', 'for')\n",
      "('for', 'something.Absolutely,')\n",
      "('something.Absolutely,', 'friendship')\n",
      "('friendship', 'is')\n",
      "('is', 'the')\n",
      "('the', 'most')\n",
      "('most', 'powerful')\n",
      "('powerful', 'magic')\n",
      "('magic', 'of')\n",
      "('of', 'all.Just')\n",
      "('all.Just', 'promise')\n",
      "('promise', 'me')\n",
      "('me', 'one')\n",
      "('one', 'thing:')\n",
      "('thing:', 'if')\n",
      "('if', 'things')\n",
      "('things', 'get')\n",
      "('get', 'tough,')\n",
      "('tough,', 'you')\n",
      "('you', \"won't\")\n",
      "(\"won't\", 'leave')\n",
      "('leave', 'me')\n",
      "('me', 'behind.I')\n",
      "('behind.I', 'promise,')\n",
      "('promise,', 'not')\n",
      "('not', 'only')\n",
      "('only', 'because')\n",
      "('because', 'of')\n",
      "('of', 'our')\n",
      "('our', 'friendship')\n",
      "('friendship', 'but')\n",
      "('but', 'also')\n",
      "('also', 'because')\n",
      "('because', \"we're\")\n",
      "(\"we're\", 'stronger')\n",
      "('stronger', 'together.Good,')\n",
      "('together.Good,', 'because')\n",
      "('because', \"we're\")\n",
      "(\"we're\", 'about')\n",
      "('about', 'to')\n",
      "('to', 'cross')\n",
      "('cross', 'the')\n",
      "('the', 'threshold,')\n",
      "('threshold,', 'and')\n",
      "('and', \"there's\")\n",
      "(\"there's\", 'no')\n",
      "('no', 'turning')\n",
      "('turning', 'back.As')\n",
      "('back.As', 'we')\n",
      "('we', 'step')\n",
      "('step', 'in,')\n",
      "('in,', 'I')\n",
      "('I', 'can')\n",
      "('can', 'feel')\n",
      "('feel', 'the')\n",
      "('the', 'energy')\n",
      "('energy', 'change.')\n",
      "('change.', 'Can')\n",
      "('Can', 'you?Yes,')\n",
      "('you?Yes,', \"it's\")\n",
      "(\"it's\", 'like')\n",
      "('like', \"we've\")\n",
      "(\"we've\", 'just')\n",
      "('just', 'walked')\n",
      "('walked', 'into')\n",
      "('into', 'another')\n",
      "('another', 'dimension.Look,')\n",
      "('dimension.Look,', \"there's\")\n",
      "(\"there's\", 'a')\n",
      "('a', 'clearing')\n",
      "('clearing', 'ahead.')\n",
      "('ahead.', 'Should')\n",
      "('Should', 'we')\n",
      "('we', 'go')\n",
      "('go', 'there?Might')\n",
      "('there?Might', 'as')\n",
      "('as', 'well,')\n",
      "('well,', 'it')\n",
      "('it', 'could')\n",
      "('could', 'be')\n",
      "('be', 'a')\n",
      "('a', 'good')\n",
      "('good', 'place')\n",
      "('place', 'to')\n",
      "('to', 'get')\n",
      "('get', 'our')\n",
      "('our', 'bearings.The')\n",
      "('bearings.The', 'clearing')\n",
      "('clearing', 'is')\n",
      "('is', 'beautiful,')\n",
      "('beautiful,', 'full')\n",
      "('full', 'of')\n",
      "('of', 'luminescent')\n",
      "('luminescent', 'plants')\n",
      "('plants', 'and')\n",
      "('and', 'mysterious')\n",
      "('mysterious', \"creatures.It's\")\n",
      "(\"creatures.It's\", 'enchanting,')\n",
      "('enchanting,', 'but')\n",
      "('but', \"let's\")\n",
      "(\"let's\", 'not')\n",
      "('not', 'forget')\n",
      "('forget', 'why')\n",
      "('why', \"we're\")\n",
      "(\"we're\", 'here.Right,')\n",
      "('here.Right,', 'we')\n",
      "('we', 'need')\n",
      "('need', 'to')\n",
      "('to', 'find')\n",
      "('find', 'the')\n",
      "('the', 'Heart')\n",
      "('Heart', 'of')\n",
      "('of', 'the')\n",
      "('the', 'Forest.')\n",
      "('Forest.', \"It's\")\n",
      "(\"It's\", 'said')\n",
      "('said', 'to')\n",
      "('to', 'grant')\n",
      "('grant', 'a')\n",
      "('a', 'single')\n",
      "('single', 'wish')\n",
      "('wish', 'to')\n",
      "('to', 'those')\n",
      "('those', 'who')\n",
      "('who', 'find')\n",
      "('find', 'it.The')\n",
      "('it.The', 'wish')\n",
      "('wish', 'can')\n",
      "('can', 'be')\n",
      "('be', 'anything?Yes,')\n",
      "('anything?Yes,', 'but')\n",
      "('but', 'it')\n",
      "('it', 'comes')\n",
      "('comes', 'with')\n",
      "('with', 'a')\n",
      "('a', 'price,')\n",
      "('price,', 'and')\n",
      "('and', 'we')\n",
      "('we', 'must')\n",
      "('must', 'be')\n",
      "('be', 'willing')\n",
      "('willing', 'to')\n",
      "('to', 'pay')\n",
      "('pay', 'it.Well,')\n",
      "('it.Well,', 'if')\n",
      "('if', \"it's\")\n",
      "(\"it's\", 'for')\n",
      "('for', 'a')\n",
      "('a', 'good')\n",
      "('good', 'cause,')\n",
      "('cause,', \"I'm\")\n",
      "(\"I'm\", 'willing')\n",
      "('willing', 'to')\n",
      "('to', 'take')\n",
      "('take', 'the')\n",
      "('the', 'risk.Me')\n",
      "('risk.Me', 'too,')\n",
      "('too,', 'but')\n",
      "('but', \"let's\")\n",
      "(\"let's\", 'be')\n",
      "('be', 'cautious.')\n",
      "('cautious.', 'The')\n",
      "('The', 'forest')\n",
      "('forest', 'is')\n",
      "('is', 'full')\n",
      "('full', 'of')\n",
      "('of', 'tricks')\n",
      "('tricks', 'and')\n",
      "('and', 'illusions.Agreed,')\n",
      "('illusions.Agreed,', 'sticking')\n",
      "('sticking', 'together')\n",
      "('together', 'is')\n",
      "('is', 'our')\n",
      "('our', 'best')\n",
      "('best', 'chance')\n",
      "('chance', 'of')\n",
      "('of', 'finding')\n",
      "('finding', 'it')\n",
      "('it', 'and')\n",
      "('and', 'making')\n",
      "('making', 'it')\n",
      "('it', 'out')\n",
      "('out', 'alive.Suddenly,')\n",
      "('alive.Suddenly,', 'a')\n",
      "('a', 'soft')\n",
      "('soft', 'voice')\n",
      "('voice', 'echoes,')\n",
      "('echoes,', \"'Who\")\n",
      "(\"'Who\", 'dares')\n",
      "('dares', 'to')\n",
      "('to', 'seek')\n",
      "('seek', 'the')\n",
      "('the', 'Heart')\n",
      "('Heart', 'of')\n",
      "('of', 'the')\n",
      "('the', \"Forest?'It\")\n",
      "(\"Forest?'It\", 'must')\n",
      "('must', 'be')\n",
      "('be', 'the')\n",
      "('the', 'Guardian.')\n",
      "('Guardian.', 'What')\n",
      "('What', 'should')\n",
      "('should', 'we')\n",
      "('we', \"say?Let's\")\n",
      "(\"say?Let's\", 'be')\n",
      "('be', 'honest.')\n",
      "('honest.', 'We')\n",
      "('We', 'seek')\n",
      "('seek', 'it')\n",
      "('it', 'to')\n",
      "('to', 'bring')\n",
      "('bring', 'balance')\n",
      "('balance', 'to')\n",
      "('to', 'our')\n",
      "('our', 'world.The')\n",
      "('world.The', 'Guardian')\n",
      "('Guardian', 'seems')\n",
      "('seems', 'pleased.')\n",
      "('pleased.', \"'Very\")\n",
      "(\"'Very\", 'well,')\n",
      "('well,', 'you')\n",
      "('you', 'may')\n",
      "('may', 'proceed.')\n",
      "('proceed.', 'But')\n",
      "('But', 'remember,')\n",
      "('remember,', 'the')\n",
      "('the', 'Heart')\n",
      "('Heart', 'will')\n",
      "('will', 'test')\n",
      "('test', 'you')\n",
      "('you', \"both.'We\")\n",
      "(\"both.'We\", 'nod,')\n",
      "('nod,', 'knowing')\n",
      "('knowing', 'the')\n",
      "('the', 'real')\n",
      "('real', 'journey')\n",
      "('journey', 'has')\n",
      "('has', 'just')\n",
      "('just', 'begun.Our')\n",
      "('begun.Our', 'hands')\n",
      "('hands', 'tighten')\n",
      "('tighten', 'around')\n",
      "('around', 'each')\n",
      "('each', \"other's.\")\n",
      "(\"other's.\", 'Whatever')\n",
      "('Whatever', 'comes')\n",
      "('comes', 'next,')\n",
      "('next,', \"we're\")\n",
      "(\"we're\", 'ready.')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "documents2 = [\n",
    "    \"I can't believe we're really doing this, going into the enchanted forest.\"\n",
    "    \"Yeah, it's been my dream since I was a kid.\"\n",
    "    \"Your dream? I thought you were afraid of magic.\"\n",
    "    \"I was, but dreams can change, can't they?\"\n",
    "    \"Sure, as long as you're ready for whatever comes next.\"\n",
    "    \"Are you saying there's something we should worry about?\"\n",
    "    \"You can never be too sure, especially when magic is involved.\"\n",
    "    \"But we have each other, right? That should count for something.\"\n",
    "    \"Absolutely, friendship is the most powerful magic of all.\"\n",
    "    \"Just promise me one thing: if things get tough, you won't leave me behind.\"\n",
    "    \"I promise, not only because of our friendship but also because we're stronger together.\"\n",
    "    \"Good, because we're about to cross the threshold, and there's no turning back.\"\n",
    "    \"As we step in, I can feel the energy change. Can you?\"\n",
    "    \"Yes, it's like we've just walked into another dimension.\"\n",
    "    \"Look, there's a clearing ahead. Should we go there?\"\n",
    "    \"Might as well, it could be a good place to get our bearings.\"\n",
    "    \"The clearing is beautiful, full of luminescent plants and mysterious creatures.\"\n",
    "    \"It's enchanting, but let's not forget why we're here.\"\n",
    "    \"Right, we need to find the Heart of the Forest. It's said to grant a single wish to those who find it.\"\n",
    "    \"The wish can be anything?\"\n",
    "    \"Yes, but it comes with a price, and we must be willing to pay it.\"\n",
    "    \"Well, if it's for a good cause, I'm willing to take the risk.\"\n",
    "    \"Me too, but let's be cautious. The forest is full of tricks and illusions.\"\n",
    "    \"Agreed, sticking together is our best chance of finding it and making it out alive.\"\n",
    "    \"Suddenly, a soft voice echoes, 'Who dares to seek the Heart of the Forest?'\"\n",
    "    \"It must be the Guardian. What should we say?\"\n",
    "    \"Let's be honest. We seek it to bring balance to our world.\"\n",
    "    \"The Guardian seems pleased. 'Very well, you may proceed. But remember, the Heart will test you both.'\"\n",
    "    \"We nod, knowing the real journey has just begun.\"\n",
    "    \"Our hands tighten around each other's. Whatever comes next, we're ready.\"\n",
    "]\n",
    "\n",
    "# Î™®Îì† Î¨∏Ïû•Ïóê ÎåÄÌï¥ N-gram Î∂ÑÏÑù ÏàòÌñâ\n",
    "for i, sentence in enumerate(documents2):\n",
    "    print(f\"--- Î¨∏Ïû• {i+1}Ïùò N-grams ---\")\n",
    "    n = 2  # bigram\n",
    "    bigrams = ngrams(sentence.split(), n)\n",
    "    for grams in bigrams:\n",
    "        print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Topic 0: 0.020*\"we're\" + 0.020*\"heart\" + 0.020*\"seek\" + 0.020*\"suddenly,\" + 0.020*\"forest?'\" + 0.020*\"dares\" + 0.020*\"sticking\" + 0.020*\"voice\" + 0.020*\"echoes,\" + 0.020*\"soft\"\n",
      "--------------------\n",
      "Topic 1: 0.034*\"we're\" + 0.034*\"there's\" + 0.020*\"comes\" + 0.018*\"whatever\" + 0.018*\"let's\" + 0.018*\"around\" + 0.018*\"ready.\" + 0.018*\"other's.\" + 0.018*\"hands\" + 0.018*\"threshold,\"\n",
      "--------------------\n",
      "Topic 2: 0.035*\"find\" + 0.019*\"wish\" + 0.019*\"heart\" + 0.019*\"it.\" + 0.019*\"single\" + 0.019*\"good\" + 0.019*\"forest.\" + 0.019*\"said\" + 0.019*\"right,\" + 0.019*\"need\"\n",
      "--------------------\n",
      "Topic 3: 0.027*\"full\" + 0.027*\"clearing\" + 0.015*\"let's\" + 0.015*\"there's\" + 0.015*\"yes,\" + 0.015*\"things\" + 0.015*\"comes\" + 0.015*\"sure,\" + 0.015*\"one\" + 0.015*\"get\"\n",
      "--------------------\n",
      "Topic 4: 0.028*\"we're\" + 0.027*\"well,\" + 0.027*\"friendship\" + 0.026*\"willing\" + 0.015*\"can't\" + 0.015*\"heart\" + 0.015*\"pleased.\" + 0.015*\"remember,\" + 0.015*\"guardian\" + 0.015*\"forest.\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "\n",
    "# Î¨∏Ïû•ÏùÑ Îã®Ïñ¥Î°ú Î∂ÑÎ¶¨Ìï©ÎãàÎã§.\n",
    "texts = [doc.lower().split() for doc in documents]\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "lda = LdaMulticore(corpus, id2word=dictionary, num_topics=5, chunksize=5)\n",
    "topics = lda.print_topics()\n",
    "for topic in topics:\n",
    "    print('-' * 20)\n",
    "    print(f\"Topic {topic[0]}: {topic[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = (\n",
    "    \"I can't believe we're really doing this, going into the enchanted forest.\"\n",
    "    \"Yeah, it's been my dream since I was a kid.\"\n",
    "    \"Your dream? I thought you were afraid of magic.\"\n",
    "    \"I was, but dreams can change, can't they?\"\n",
    "    \"Sure, as long as you're ready for whatever comes next.\"\n",
    "    \"Are you saying there's something we should worry about?\"\n",
    "    \"You can never be too sure, especially when magic is involved.\"\n",
    "    \"But we have each other, right? That should count for something.\"\n",
    "    \"Absolutely, friendship is the most powerful magic of all.\"\n",
    "    \"Just promise me one thing: if things get tough, you won't leave me behind.\"\n",
    "    \"I promise, not only because of our friendship but also because we're stronger together.\"\n",
    "    \"Good, because we're about to cross the threshold, and there's no turning back.\"\n",
    "    \"As we step in, I can feel the energy change. Can you?\"\n",
    "    \"Yes, it's like we've just walked into another dimension.\"\n",
    "    \"Look, there's a clearing ahead. Should we go there?\"\n",
    "    \"Might as well, it could be a good place to get our bearings.\"\n",
    "    \"The clearing is beautiful, full of luminescent plants and mysterious creatures.\"\n",
    "    \"It's enchanting, but let's not forget why we're here.\"\n",
    "    \"Right, we need to find the Heart of the Forest. It's said to grant a single wish to those who find it.\"\n",
    "    \"The wish can be anything?\"\n",
    "    \"Yes, but it comes with a price, and we must be willing to pay it.\"\n",
    "    \"Well, if it's for a good cause, I'm willing to take the risk.\"\n",
    "    \"Me too, but let's be cautious. The forest is full of tricks and illusions.\"\n",
    "    \"Agreed, sticking together is our best chance of finding it and making it out alive.\"\n",
    "    \"Suddenly, a soft voice echoes, 'Who dares to seek the Heart of the Forest?'\"\n",
    "    \"It must be the Guardian. What should we say?\"\n",
    "    \"Let's be honest. We seek it to bring balance to our world.\"\n",
    "    \"The Guardian seems pleased. 'Very well, you may proceed. But remember, the Heart will test you both.'\"\n",
    "    \"We nod, knowing the real journey has just begun.\"\n",
    "    \"Our hands tighten around each other's. Whatever comes next, we're ready.\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('enchanted forest', 0.3829), ('absolutely friendship', 0.3753), ('the enchanted', 0.3745), ('powerful magic', 0.3717), ('enchanted', 0.368)]\n"
     ]
    }
   ],
   "source": [
    "model = KeyBERT()\n",
    "\n",
    "keywords = model.extract_keywords(test1, keyphrase_ngram_range=(1, 2), stop_words=None)\n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
